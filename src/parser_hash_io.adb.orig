------------------------------------------------------------------------------
-- Berekeley Hash Files Package Parser                                      --
--                                                                          --
-- Part of SparForte                                                        --
------------------------------------------------------------------------------
--                                                                          --
--            Copyright (C) 2001-2022 Free Software Foundation              --
--                                                                          --
-- This is free software;  you can  redistribute it  and/or modify it under --
-- terms of the  GNU General Public License as published  by the Free Soft- --
-- ware  Foundation;  either version 2,  or (at your option) any later ver- --
-- sion.  This is distributed in the hope that it will be useful, but WITH- --
-- OUT ANY WARRANTY;  without even the  implied warranty of MERCHANTABILITY --
-- or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License --
-- for  more details.  You should have  received  a copy of the GNU General --
-- Public License  distributed with this;  see file COPYING.  If not, write --
-- to  the Free Software Foundation,  59 Temple Place - Suite 330,  Boston, --
-- MA 02111-1307, USA.                                                      --
--                                                                          --
-- This is maintained at http://www.sparforte.com                           --
--                                                                          --
------------------------------------------------------------------------------
pragma ada_2005;

--with text_io;use text_io;

with
    Interfaces.C,
    gnat.directory_operations,
    gnat.source_info,
    ada.exceptions,
    ada.strings.unbounded,
    pegasoft.user_io,
    world,
    scanner,
    scanner.communications,
    scanner_res,
    scanner_restypes,
    parser,
    parser_params,
    parser_bdb;

#if BDB
with
    bdb,
    bdb_constants;
#end if;

use
    gnat.directory_operations,
    ada.exceptions,
    ada.strings.unbounded,
    world,
    pegasoft.user_io,
    scanner,
    scanner.communications,
    scanner_res,
    scanner_restypes,
    parser,
    parser_params,
    parser_bdb;
#if BDB
use
    bdb,
    bdb_constants;
#end if;

package body parser_hash_io is

------------------------------------------------------------------------------
-- Hash package identifiers
------------------------------------------------------------------------------

--hash_new_file_t      : identifier;
hash_clear_t         : identifier;

hash_will_raise_t    : identifier;
hash_last_error_t    : identifier;
hash_raise_exceptions_t : identifier;

hash_recover_t       : identifier;
hash_create_t        : identifier;
hash_close_t         : identifier;
hash_open_t          : identifier;
hash_delete_t        : identifier;
hash_is_open_t       : identifier;
hash_name_t          : identifier;
hash_flush_t         : identifier;
hash_truncate_t      : identifier;

hash_set_t           : identifier;
hash_get_t           : identifier;
hash_has_element_t   : identifier;
hash_remove_t        : identifier;
hash_increment_t     : identifier;
hash_decrement_t     : identifier;
hash_add_t           : identifier;
hash_replace_t       : identifier;
hash_append_t        : identifier;
hash_prepend_t       : identifier;

--hash_new_cursor_t    : identifier;
hash_open_cursor_t   : identifier;
hash_close_cursor_t  : identifier;
hash_get_first_t     : identifier;
hash_get_last_t      : identifier;
hash_get_next_t      : identifier;
hash_get_previous_t  : identifier;

------------------------------------------------------------------------------
-- Utility subprograms
------------------------------------------------------------------------------

procedure ParseSingleFileParameter( subprogram : identifier; fileId : out identifier ) is
begin
  ParseSingleInOutInstantiatedParameter( subprogram, fileId, hash_file_t );
end ParseSingleFileParameter;

procedure ParseFirstFileParameter( subprogram : identifier; fileId : out identifier ) is
begin
  ParseFirstInOutInstantiatedParameter( subprogram, fileId, hash_file_t );
end ParseFirstFileParameter;

--procedure ParseNextFileParameter( fileId : out identifier ) is
--begin
--  ParseNextInOutInstantiatedParameter( fileId, hash_file_t );
--end ParseNextFileParameter;
--
--procedure ParseLastFileParameter( fileId : out identifier ) is
--begin
--  ParseLastInOutInstantiatedParameter( fileId, hash_file_t );
--end ParseLastFileParameter;

------------------------------------------------------------------------------

--procedure ParseSingleCursorParameter( cursId : out identifier ) is
--begin
--  ParseSingleInOutInstantiatedParameter( cursId, hash_cursor_t );
--end ParseSingleCursorParameter;

--procedure ParseFirstCursorParameter( cursId : out identifier ) is
--begin
--  ParseFirstInOutInstantiatedParameter( cursId, hash_cursor_t );
--end ParseFirstCursorParameter;

procedure ParseNextCursorParameter( subprogram : identifier; cursId : out identifier ) is
begin
  ParseNextInOutInstantiatedParameter( subprogram, cursId, hash_cursor_t );
end ParseNextCursorParameter;

procedure ParseLastCursorParameter( subprogram : identifier; cursId : out identifier ) is
begin
  ParseLastInOutInstantiatedParameter( subprogram, cursId, hash_cursor_t );
end ParseLastCursorParameter;

#if BDB
-- IS VERIFIED OPEN FILE
--
-- True if the file is open, otherwise an error occurs and false is returned.
------------------------------------------------------------------------------

function isVerifiedOpenFile( fileId : identifier; theFile : resPtr ) return boolean is
  result : boolean := true;
begin
   if not theFile.hash.isOpen then
      err( "file " &
      optional_yellow( to_string( identifiers( fileId ).name ) ) &
      " is not open" );
      result := false;
   end if;
   return result;
end isVerifiedOpenFile;

-----------------------------------------------------------------------------
--  CONFIGURE DBD ENV
--
-- Berkeley puts the files in the current directory, though you can
-- move the env because it is shared.  To put the project in a specific
-- directory, you have you configure it.  A sophisiticated setup would
-- place all of these in different directories.
--
-- For our purposes (simple files), keep everything in one directory
-----------------------------------------------------------------------------

procedure configureBDBEnv( env : in out bdb.berkeley_environment; dirname : string ) is
begin
   if dirname'length > 0 then
      begin
         set_data_dir( env, dirname );
      exception when msg: berkeley_error =>
         err( exception_message( msg ) & " on setting the data directory" );
      end;
      begin
         set_tmp_dir( env, dirname );
      exception when msg: berkeley_error =>
         err( exception_message( msg ) & " on setting the temp directory"  );
      end;
      begin
         set_lg_dir( env, dirname );
      exception when msg: berkeley_error =>
         err( exception_message( msg ) & " on setting the logging directory"  );
      end;
      begin
         if verboseOpt then
            set_verbose( env, DB_VERB_BACKUP, 1 );
            set_verbose( env, DB_VERB_DEADLOCK, 1 );
            set_verbose( env, DB_VERB_FILEOPS_ALL, 1 );
            set_verbose( env, DB_VERB_WAITSFOR, 1 );
         end if;
      exception when msg: berkeley_error =>
         err( exception_message( msg ) & " on changing verbose setting"  );
      end;
   end if;
end configureBDBEnv;

#end if;

------------------------------------------------------------------------------
-- Parser subprograms
------------------------------------------------------------------------------

#if BDB

--procedure ParseHashNewFile is
--  -- Syntax: hash.new_file( f, t );
--  -- Ada:    N/A
--  resId : resHandleId;
--  ref : reference;
--  genKindId : identifier;
--  theFile : resPtr;
--begin
--  expect( hash_new_file_t );
--  ParseFirstOutParameter( ref, hash_file_t );
--  baseTypesOK( ref.kind, hash_file_t );
--  expect( symbol_t, "," );
--  ParseIdentifier( genKindId );
--  if class_ok( genKindId, typeClass, subClass ) then
--     -- DEBUG: trying aggregates
--     null;
--     --if identifiers( genKindId ).list then
--     --   err( "element type should be a scalar type" );
--     -- elsif identifiers( getBaseType( genKindId ) ).kind = root_record_t then
--     --    err( "element type should be a scalar type" );
--     --end if;
--  end if;
--  identifiers( ref.id ).genKind := genKindId;
--  expect( symbol_t, ")" );
--  if isExecutingCommand then
--     identifiers( ref.id ).resource := true;
--     declareResource( resId, hash_file, getIdentifierBlock( ref.id ) );
--     AssignParameter( ref, to_unbounded_string( resId ) );
--     -- TODO: this won't work if the cursor is in an array or other
--     -- aggregate type
--     identifiers( ref.id ).wasWritten := true;
--     findResource( resId, theFile );
--     theFile.hash.isOpen := false;
--  end if;
--end ParseHashNewFile;

#else

pragma warnings( off );
-- Hide unused parameters warnings

procedure not_configured is
begin
  err( "Berkeley DB support not configured" );
end not_configured;

procedure not_configured( result : out unbounded_string; kind : out identifier ) is
begin
  err( "Berkeley DB support not configured" );
end not_configured;

--procedure ParseHashNewFile renames not_configured;

#end if;
#if BDB

procedure ParseHashClear is
  -- Syntax: hash.clear( f );
  -- Ada:    N/A;
  fileId   : identifier;
  theFile  : resPtr;
begin
  expect( hash_clear_t );
  ParseSingleFileParameter( hash_clear_t, fileId );
  if isExecutingCommand then
     begin
       -- close the file / environment, if they are still open.  This doesn't
       -- close any cursors.
       findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
       if theFile.hash.isOpen then
          Close( theFile.hash.session );
          Close( theFile.hash.env );
          theFile.hash.isOpen := false;
       end if;
     exception when msg: berkeley_error =>
       err( exception_message( msg ) );
     end;
  end if;
end ParseHashClear;

#else

procedure ParseHashClear renames not_configured;

#end if;
#if BDB

-----------------------------------------------------------------------------
--  PARSE HASH RECOVER
--
-- Syntax: hash.recover( f, fname );
-- Ada:    N/A;
-----------------------------------------------------------------------------

procedure ParseHashRecover is
  fileId     : identifier;
  theFile    : resPtr;
  fname_val  : unbounded_string;
  fname_type : identifier;
begin
  if rshOpt then
     err( "recover not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_recover_t );
  ParseFirstFileParameter( hash_recover_t, fileId );
  ParseLastStringParameter( hash_recover_t, fname_val, fname_type, string_t );


  if isExecutingCommand then
     declare
        filename : constant string := base_name( to_string( fname_val ) );
        dirname  : constant string := dir_name( to_string( fname_val ) );
        dirname2 : unbounded_string;
        pwdId : identifier;
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        init( theFile.hash.env );

        -- berkeley db paths must be absolute paths when creating (opening
        -- an exisiting data file is OK for relative paths)

        dirname2 := to_unbounded_string( dirname );
        if dirname = "." then
           dirname2 := null_unbounded_string;
        elsif element( dirname2, 1 ) /= '/' then
           findIdent( to_unbounded_string( "PWD" ), pwdId );
           dirname2 := identifiers( pwdId ).value.all & "/" & dirname;
        end if;
        if trace then
           put_trace( "Base directory is '" & to_string( dirname2 ) & "'" );
        end if;

        configureBDBEnv( theFile.hash.env, to_string( dirname2 ) );

        -- To recover, open a new environment in recovery mode.  Transactions
        -- must be enabled.  This will recreate the environment files.

        begin
           create( theFile.hash.env,
                   to_string( dirname2 ),
                   DB_E_OPEN_RECOVER OR
                   DB_E_OPEN_INIT_TXN OR
                   DB_E_OPEN_INIT_LOCK OR
                   DB_E_OPEN_INIT_MPOOL,
                   0 );
           close( theFile.hash.env );
        exception when msg: berkeley_error =>
            err( exception_message( msg ) & " on recovering the environment" );
        end;
     end;
  end if; -- is executing command
end ParseHashRecover;

#else

procedure ParseHashRecover renames not_configured;

#end if;
#if BDB

procedure ParseHashCreate is
  -- Syntax: hash.create( f, path, keyLen, valLen );
  -- Ada:    hash.create( f, path, keyLen, valLen );
  -- this is impacted by --verbse
  fileId     : identifier;
  theFile    : resPtr;
  fname_val  : unbounded_string;
  fname_type : identifier;
  keyLen     : interfaces.C.size_t;
  keyLenExpr : unbounded_string;
  keyLenType : identifier;
  valLen     : interfaces.C.size_t;
  valLenExpr : unbounded_string;
  valLenType : identifier;
begin
  if rshOpt then
     err( "create not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_create_t );
  -- NOTE: normally this is an out parameter but it is a resource so it
  -- must be initialized separately.
  ParseFirstFileParameter( hash_create_t, fileId );
  ParseNextStringParameter( hash_create_t, fname_val, fname_type, string_t );
  ParseNextNumericParameter( hash_create_t, keyLenExpr, keyLenType, positive_t );
  ParseLastNumericParameter( hash_create_t, valLenExpr, valLenType, positive_t );
  if isExecutingCommand then
     begin
        keyLen := Interfaces.C.size_t'value( to_string( keyLenExpr ) );
     exception when others =>
        err( "key length must be" & Interfaces.C.size_t'first'img & ".." & Interfaces.C.size_t'last'img );
     end;
     begin
        valLen := Interfaces.C.size_t'value( to_string( valLenExpr ) );
     exception when others =>
        err( "value length must be" & Interfaces.C.size_t'first'img & ".." & Interfaces.C.size_t'last'img );
     end;

     declare
        -- GNAT 7.4 incorrectly states filename is not used
        filename : constant string := base_name( to_string( fname_val ) );
        dirname  : constant string := dir_name( to_string( fname_val ) );
        dirname2 : unbounded_string;
        pwdId : identifier;
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );

        init( theFile.hash.env );

        -- berkeley db paths must be absolute paths when creating (opening
        -- an exisiting data file is OK for relative paths)

        dirname2 := to_unbounded_string( dirname );
        if dirname = "." then
           dirname2 := null_unbounded_string;
        elsif element( dirname2, 1 ) /= '/' then
           findIdent( to_unbounded_string( "PWD" ), pwdId );
           dirname2 := identifiers( pwdId ).value.all & "/" & dirname;
        end if;
        if trace then
           put_trace( "Base directory is '" & to_string( dirname2 ) & "'" );
        end if;

        configureBDBEnv( theFile.hash.env, to_string( dirname2 ) );

        -- Create an environment

        if theFile.hash.isOpen then
           err( "file " &
              optional_yellow( to_string( identifiers( fileId ).name ) ) &
              "(" & ASCII.Quotation & to_string( theFile.hash.name ) & ASCII.Quotation & ") " &
              " is already open" );
        else
           begin
              create( theFile.hash.env,
                   to_string( dirname2 ),
                   -- I assume we don't need logging or transactions but
                   -- they could be implemented.
                   DB_E_OPEN_INIT_LOCK OR
                   DB_E_OPEN_INIT_MPOOL,
                   0 );
              theFile.hash.envhome := dirname2;
              exception when msg: berkeley_error =>
                 err( exception_message( msg ) & " on creating the environment" );
              end;

           -- Create the file
           new_berkeley_session(
              theFile.hash.session,
              theFile.hash.env,
              keyLen,
              valLen );
           begin
              create( theFile.hash.session, filename, "", DB_HASH, 0, 0 );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on creating the data file"  );
           end;

           -- Do not truncate if create failed

           if not error_found then
              theFile.hash.isOpen := true;
              theFile.hash.name := fname_val;
              declare
                 cnt : natural;
              begin
                 truncate( theFile.hash.session, cnt );
                 if trace and cnt > 0 then
                    put_trace( cnt'img & " records were erased" );
                 end if;
              exception when msg: berkeley_error =>
                 err( exception_message( msg ) & " on truncating the data file"  );
              end;
           end if;
       end if;
     --exception when berkeley_error:s =>
     --   err( to_string( last_error( theFile.hash.session ) );
     end;
  end if;
end ParseHashCreate;

#else

procedure ParseHashCreate renames not_configured;

#end if;
#if BDB

procedure ParseHashClose is
  -- Syntax: hash.create( f );
  -- Ada:    hash.create( f );
  fileId     : identifier;
  theFile    : resPtr;
begin
  expect( hash_close_t );
  ParseSingleFileParameter( hash_close_t, fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if theFile.hash.isOpen then
           close( theFile.hash.session );
           close( theFile.hash.env );
           theFile.hash.isOpen := false;
        else
           err( "file " &
              optional_yellow( to_string( identifiers( fileId ).name ) ) &
              "(" & ASCII.Quotation & to_string( theFile.hash.name ) & ASCII.Quotation & ") " &
               " is not open" );
        end if;
      exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashClose;

#else

procedure ParseHashClose renames not_configured;

#end if;
#if BDB

procedure ParseHashOpen is
  -- Syntax: hash.open( f, path, keyLen, valLen );
  -- Ada:    hash.open( f, path, keyLen, valLen );
  -- this is impacted by --verbse
  fileId     : identifier;
  theFile    : resPtr;
  fname_val  : unbounded_string;
  fname_type : identifier;
  keyLen     : interfaces.C.size_t;
  keyLenExpr : unbounded_string;
  keyLenType : identifier;
  valLen     : interfaces.C.size_t;
  valLenExpr : unbounded_string;
  valLenType : identifier;
begin
  expect( hash_open_t );
  -- NOTE: normally this is an out parameter but it is a resource so it
  -- must be initialized separately.
  ParseFirstFileParameter( hash_open_t, fileId );
  ParseNextStringParameter( hash_open_t, fname_val, fname_type, string_t );
  -- TODO: can this be dynamic?
  ParseNextNumericParameter( hash_open_t, keyLenExpr, keyLenType, positive_t );
  ParseLastNumericParameter( hash_open_t, valLenExpr, valLenType, positive_t );
  if isExecutingCommand then
     begin
        keyLen := Interfaces.C.size_t'value( to_string( keyLenExpr ) );
     exception when others =>
        err( "key length must be" & Interfaces.C.size_t'first'img & ".." & Interfaces.C.size_t'last'img );
     end;
     begin
        valLen := Interfaces.C.size_t'value( to_string( valLenExpr ) );
     exception when others =>
        err( "value length must be" & Interfaces.C.size_t'first'img & ".." & Interfaces.C.size_t'last'img );
     end;

     declare
        -- GNAT 7.4 incorrectly states filename is not used
        filename : constant string := base_name( to_string( fname_val ) );
        dirname  : constant string := dir_name( to_string( fname_val ) );
        dirname2 : unbounded_string;
        pwdId : identifier;
     begin
        -- TODO: pathname handling
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );

        -- Create an environment
        init( theFile.hash.env );

        -- berkeley db paths must be absolute paths when creating (opening
        -- an exisiting data file is OK for relative paths).  We're doing this
        -- here to be consistent with create but it shouldn't be necessary

        dirname2 := to_unbounded_string( dirname );
        if dirname = "." then
           dirname2 := null_unbounded_string;
        elsif rshOpt then
           -- TODO: probably could be in directories in current PATH as well
           err( "file must be in current directory in a " & optional_yellow( "restricted shell" ) );
        elsif element( dirname2, 1 ) /= '/' then
           findIdent( to_unbounded_string( "PWD" ), pwdId );
           dirname2 := identifiers( pwdId ).value.all & "/" & dirname;
        end if;
        if trace then
           put_trace( "Base directory is '" & to_string( dirname2 ) & "'" );
        end if;

        configureBDBEnv( theFile.hash.env, to_string( dirname2 ) );

        if theFile.hash.isOpen then
           err( "file " &
              optional_yellow( to_string( identifiers( fileId ).name ) ) &
              "(" & ASCII.Quotation & to_string( theFile.hash.name ) & ASCII.Quotation & ") " &
              " is already open" );
        else
           begin
              open( theFile.hash.env,
                   to_string( dirname2 ),
                   -- I assume we don't need logging or transactions but
                   -- they could be implemented.
                   DB_E_OPEN_INIT_LOCK OR
                   DB_E_OPEN_INIT_MPOOL,
                   0 );
              theFile.hash.envhome := dirname2;
              exception when msg: berkeley_error =>
                 err( exception_message( msg ) & " on opening the environment" );
              end;

           if not error_found then
              -- Create the file
              new_berkeley_session(
                 theFile.hash.session,
                 theFile.hash.env,
                 keyLen,
                 valLen );

              begin
                 open( theFile.hash.session, filename, "", DB_HASH, 0, 0 );
                 theFile.hash.isOpen := true;
                 theFile.hash.name := fname_val;
              exception when msg: berkeley_error =>
                 err( exception_message( msg ) & " on opening the data file"  );
              end;
           end if;
        end if;
     end;
  end if;
end ParseHashOpen;

#else

procedure ParseHashOpen renames not_configured;

#end if;
#if BDB

procedure ParseHashIsOpen( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: b := hash.is_open( f );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
begin
  kind := boolean_t;
  expect( hash_is_open_t );
  ParseSingleFileParameter( hash_is_open_t, fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        result := to_bush_boolean( theFile.hash.isOpen );
     exception when berkeley_error =>
        result := to_bush_boolean( false );
     end;
  end if;
end ParseHashIsOpen;

#else

procedure ParseHashIsOpen( result : out unbounded_string; kind : out identifier ) renames not_configured;

#end if;
#if BDB

procedure ParseHashName( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: b := hash.name( f );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
begin
  kind := string_t;
  expect( hash_name_t );
  ParseSingleFileParameter( hash_name_t, fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        result := theFile.hash.name;
     end;
  end if;
end ParseHashName;

#else

procedure ParseHashName( result : out unbounded_string; kind : out identifier ) renames not_configured;

#end if;
#if BDB

procedure ParseHashDelete is
  -- Syntax: hash.delete( f );
  -- Ada:    bdb.remove( f );
  -- TODO:   option to the keep environment in case other files use it
  fileId     : identifier;
  theFile    : resPtr;
  dirname2   : unbounded_string;
begin
  if rshOpt then
     err( "delete not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_delete_t );
  ParseSingleFileParameter( hash_delete_t, fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if theFile.hash.isOpen then
           begin
              close( theFile.hash.session );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on closing the data file"  );
           end;
        end if;

        -- Close closes the environment.  We need to reopen it.

        declare
           dirname  : constant string := dir_name( to_string( theFile.hash.name ) );
           pwdId : identifier;
        begin
           -- TODO: pathname handling
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );

           -- Create an environment
           init( theFile.hash.env );

           -- berkeley db paths must be absolute paths when creating (opening
           -- an exisiting data file is OK for relative paths).  We're doing this
           -- here to be consistent with create but it shouldn't be necessary

           dirname2 := to_unbounded_string( dirname );
           if dirname = "." then
              dirname2 := null_unbounded_string;
           elsif rshOpt then
              -- TODO: probably could be in directories in current PATH as well
              err( "file must be in current directory in a " & optional_yellow( "restricted shell" ) );
           elsif element( dirname2, 1 ) /= '/' then
              findIdent( to_unbounded_string( "PWD" ), pwdId );
              dirname2 := identifiers( pwdId ).value.all & "/" & dirname;
           end if;
           if trace then
              put_trace( "Base directory is '" & to_string( dirname2 ) & "'" );
           end if;

           configureBDBEnv( theFile.hash.env, to_string( dirname2 ) );
        end;
        begin
           open( theFile.hash.env,
                to_string( dirname2 ),
                -- I assume we don't need logging or transactions but
                -- they could be implemented.
                DB_E_OPEN_INIT_LOCK OR
                DB_E_OPEN_INIT_MPOOL,
                0 );
           theFile.hash.envhome := dirname2;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) & " on opening the environment" );
        end;

        begin
           dbremove( theFile.hash.env,
             --to_string( theFile.hash.name ),
             --TODO: this is calculated above
             base_name( to_string( theFile.hash.name ) ),
             "",
             0 );
        exception when msg: berkeley_error =>
            err( exception_message( msg ) & " on removing the data file"  );
        end;

        begin
           --init( theFile.hash.env );
           close( theFile.hash.env );
           --remove( theFile.hash.env, to_string( theFile.hash.envhome ) );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) & " on removing the environment"  );
        end;
        theFile.hash.isOpen := false;
     exception when storage_error =>
        err( "storage_error raised" );
     when constraint_error =>
        err( "constraint_error raised" );
     when others =>
        err_exception_raised;
     end;
  end if;
end ParseHashDelete;

#else

procedure ParseHashDelete renames not_configured;

#end if;
#if BDB

procedure ParseHashSet is
  -- Syntax: hash.set( f, key, value );
  -- Ada:    bdb.put( f, key, value );
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr    : unbounded_string;
  keyType    : identifier;
  valExpr    : unbounded_string;
  valType    : identifier;
  valId      : identifier;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "set not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_set_t );
  ParseFirstFileParameter( hash_set_t, fileId );
  ParseNextStringParameter( hash_set_t, keyExpr, keyType, string_t );
  expectParameterComma;
  genKindId := identifiers( fileId ).genKind;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     isRecord := true;
     ParseIdentifier( valId );
     genTypesOk( identifiers( valId ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     isArray := true;
     ParseIdentifier( valId );
     genTypesOk( identifiers( valId ).kind, genKindId );
  -- normal (scalar) expression?
  else
    ParseGenItemParameter( valExpr, valType, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              jsonString : unbounded_string;
           begin
              DoRecordToJson( jsonString, valId );
              put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) );
           when CONSTRAINT_ERROR =>
              err( "constraint_error: value too big" );
           end;
        end if;
     elsif isArray then
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              jsonString : unbounded_string;
           begin
              DoArrayToJson( jsonString, valId );
              put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) );
           when CONSTRAINT_ERROR =>
              err( "constraint_error: value too big" );
           end;
        end if;
     else
        -- normal scalar expression
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           begin
              put( theFile.hash.session, to_string( keyExpr ), to_string( valExpr ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) );
           when STORAGE_ERROR =>
              err( gnat.source_info.source_location & ": internal error: unable to reference BDB session" );
           when CONSTRAINT_ERROR =>
              err( "constraint_error: value too big" );
           end;
        end if;
     end if;
  end if;
end ParseHashSet;

#else

procedure ParseHashSet renames not_configured;

#end if;
#if BDB

procedure ParseHashGet is
  -- Syntax: hash.get( f, k, v );
  -- Ada:    v := bdb.get( f, k );
  -- This was originally a function but turned into a procedure because
  -- v can now be an aggregate (and we currently cannot return aggregates
  -- from a function)
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr    : unbounded_string;
  keyType    : identifier;
  itemRef    : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  -- TODO: null string instead of exception to parallel dht
  expect( hash_get_t );
  ParseFirstFileParameter( hash_get_t, fileId );
  genKindId := identifiers( fileId ).genKind;
  ParseNextStringParameter( hash_get_t, keyExpr, keyType, string_t );
  expectParameterComma;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( itemRef.id );
     genTypesOk( identifiers( itemRef.id ).kind, genKindId );
     -- Mark the variable as having been written for future tests.
     if syntax_check and then not error_found then
        if identifiers( itemRef.id ).field_of /= eof_t then
           identifiers( identifiers( itemRef.id ).field_of ).wasWritten := true;
           identifiers( identifiers( itemRef.id ).field_of ).writtenByThread := getThreadName;
        else
           identifiers( itemRef.id ).wasWritten := true;
           identifiers( itemRef.id ).writtenByThread := getThreadName;
        end if;
     end if;
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( itemRef.id );
     genTypesOk( identifiers( itemRef.id ).kind, genKindId );
     --ParseLastOutParameter(  itemRef, genKindId );
     -- Mark the variable as having been written for future tests.
     if syntax_check and then not error_found then
        if identifiers( itemRef.id ).field_of /= eof_t then
           identifiers( identifiers( itemRef.id ).field_of ).wasWritten := true;
           identifiers( identifiers( itemRef.id ).field_of ).writtenByThread := getThreadName;
        else
           identifiers( itemRef.id ).wasWritten := true;
           identifiers( itemRef.id ).wasWritten := true;
        end if;
     end if;
  else
     -- This will still auto-declare scalars
     ParseOutParameter(  itemRef, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              jsonString : unbounded_string;
           begin
              get( theFile.hash.session, to_string( keyExpr ), jsonString );
              DoJsonToRecord( itemRef.id, jsonString );
           exception when msg: berkeley_error =>
              if last_error( theFile.hash.session ) = DB_NOTFOUND then
                 err( "key not found" );
              else
                  err( exception_message( msg ) );
              end if;
           when STORAGE_ERROR =>
              err( gnat.source_info.source_location & ": internal error: unable to reference BDB session" );
           end;
        end if;
     elsif isArray then
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              jsonString : unbounded_string;
           begin
              get( theFile.hash.session, to_string( keyExpr ), jsonString );
              DoJsonToArray( itemRef.id, jsonString );
           exception when msg: berkeley_error =>
              if last_error( theFile.hash.session ) = DB_NOTFOUND then
                 err( "key not found" );
              else
                  err( exception_message( msg ) );
              end if;
           when STORAGE_ERROR =>
              err( gnat.source_info.source_location & ": internal error: unable to reference BDB session" );
           end;
        end if;
     else
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              result : unbounded_string;
           begin
              get( theFile.hash.session, to_string( keyExpr ), result );
              AssignParameter( itemRef, result );
           exception when msg: berkeley_error =>
              if last_error( theFile.hash.session ) = DB_NOTFOUND then
                 err( "key not found" );
              else
                  err( exception_message( msg ) );
              end if;
           when STORAGE_ERROR =>
              err( gnat.source_info.source_location & ": internal error: unable to reference BDB session" );
           end;
        end if;
     end if;
  end if;
end ParseHashGet;

#else

procedure ParseHashGet renames not_configured;

#end if;
#if BDB

procedure ParseHashHasElement( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: v := hash.has_element( f, k );
  -- Ada:    bdb.exists( f, k );
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr    : unbounded_string;
  keyType    : identifier;
begin
  kind := boolean_t;
  expect( hash_has_element_t );
  ParseFirstFileParameter( hash_has_element_t, fileId );
  ParseLastStringParameter( hash_has_element_t, keyExpr, keyType, string_t );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
        begin
           exists( theFile.hash.session, to_string( keyExpr ) );
           result := to_bush_boolean( true );
        exception when berkeley_error =>
           result := to_bush_boolean( false );
        when STORAGE_ERROR =>
           err( gnat.source_info.source_location & ": internal error: unable to reference BDB session" );
        end;
     end if;
  end if;
end ParseHashHasElement;

#else

procedure ParseHashHasElement( result : out unbounded_string; kind : out identifier ) renames not_configured;

#end if;
#if BDB

procedure ParseHashRemove is
  -- Syntax: v := hash.remove( f, k | c );
  -- Ada:    bdb.delete( f, k | c );
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier := eof_t;
  theCurs    : resPtr;
  keyExpr    : unbounded_string;
  keyType    : identifier;
begin
  if rshOpt then
     err( "remove not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_remove_t );
  ParseFirstFileParameter( hash_remove_t, fileId );
  expectParameterComma;
  if getbaseType( identifiers( token ).kind ) = hash_cursor_t then
     ParseIdentifier( cursId );
     genTypesOk( identifiers( fileId ).genKind, identifiers( cursId ).genKind );
  else
     ParseExpression( keyExpr, keyType );
     baseTypesOk( keyType, uni_string_t );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
        if cursId /= eof_t then
           begin
             findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
             delete( theFile.hash.session, theCurs.hash_cur.cursor );
           exception when msg: berkeley_error =>
               err( exception_message( msg ) );
           end;
        else
           begin
              delete( theFile.hash.session, to_string( keyExpr ) );
           exception when msg: berkeley_error =>
              if last_error( theFile.hash.session ) = DB_NOTFOUND then
                 err( "key not found" );
              else
                 err( exception_message( msg ) );
              end if;
           when STORAGE_ERROR =>
              err( gnat.source_info.source_location & ": internal error: unable to reference BDB session" );
           end;
        end if;
     end if;
  end if;
end ParseHashRemove;

#else

procedure ParseHashRemove renames not_configured;

#end if;
#if BDB

procedure ParseHashIncrement is
  -- Syntax: hash.increment( f, s [,n] );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  amtExpr  : unbounded_string;
  amtType  : identifier;
  hasAmt   : boolean := false;
  oldItem  : unbounded_string;
  oldItemValue : long_float;
begin
  if rshOpt then
     err( "increment not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_increment_t );
  ParseFirstFileParameter( hash_increment_t, fileId );
  if getUniType( identifiers( fileId ).genKind ) /= uni_numeric_t then
     err( "increment requires a numeric item type" );
  end if;
  ParseNextStringParameter( hash_increment_t, keyExpr, keyType, uni_string_t );
  if token = symbol_t and identifiers( token ).value.all = "," then
     hasAmt := true;
     ParseLastNumericParameter( hash_increment_t, amtExpr, amtType, natural_t );
  elsif token = symbol_t and identifiers( token ).value.all = ")" then
     expect( symbol_t, ")" );
  else
     err( ", or ) expected" );
  end if;
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
        begin
          get( theFile.hash.session, to_string( keyExpr ), oldItem );

          -- berkeley throws exception on not found
          --if oldItem /= null_unbounded_string then
          oldItemValue := to_numeric( oldItem );
          if hasAmt then
             put( theFile.hash.session, to_string( keyExpr ),  to_string( to_unbounded_string( oldItemValue + long_float( natural( to_numeric( amtExpr ) ) ) ) ) );
          else
             put( theFile.hash.session, to_string( keyExpr ), to_string( to_unbounded_string( oldItemValue + 1.0 ) ) );
          end if;
          --end if;
        exception when storage_error =>
          err( "storage error raised" );
        when constraint_error =>
          err( "constraint error raised" );
        when msg: berkeley_error =>
          if last_error( theFile.hash.session ) = DB_NOTFOUND then
             err( "key not found" );
          else
             err( exception_message( msg ) );
          end if;
        end;
     end if;
  end if;
end ParseHashIncrement;

#else

procedure ParseHashIncrement renames not_configured;

#end if;
#if BDB

procedure ParseHashDecrement is
  -- Syntax: hash.decrement( f, s [,n] );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  amtExpr  : unbounded_string;
  amtType  : identifier;
  hasAmt   : boolean := false;
  oldItem  : unbounded_string;
  oldItemValue : long_float;
begin
  if rshOpt then
     err( "decrement not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_decrement_t );
  ParseFirstFileParameter( hash_decrement_t, fileId );
  if getUniType( identifiers( fileId ).genKind ) /= uni_numeric_t then
     err( "increment requires a numeric item type" );
  end if;
  ParseNextStringParameter( hash_decrement_t, keyExpr, keyType, uni_string_t );
  if token = symbol_t and identifiers( token ).value.all = "," then
     hasAmt := true;
     ParseLastNumericParameter( hash_decrement_t, amtExpr, amtType, natural_t );
  elsif token = symbol_t and identifiers( token ).value.all = ")" then
     expect( symbol_t, ")" );
  else
     err( ", or ) expected" );
  end if;
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
       begin
         get( theFile.hash.session, to_string( keyExpr ), oldItem );
         -- berkeley throws exception on not found
         --if oldItem /= null_unbounded_string then
         oldItemValue := to_numeric( oldItem );
         if hasAmt then
            put( theFile.hash.session, to_string( keyExpr ),  to_string( to_unbounded_string( oldItemValue - long_float( natural( to_numeric( amtExpr ) ) ) ) ) );
         else
            put( theFile.hash.session, to_string( keyExpr ), to_string( to_unbounded_string( oldItemValue - 1.0 ) ) );
         end if;
         --end if;
       exception when storage_error =>
          err( "storage error raised" );
       when constraint_error =>
          err( "constraint error raised" );
       when msg: berkeley_error =>
          if last_error( theFile.hash.session ) = DB_NOTFOUND then
             err( "key not found" );
          else
             err( exception_message( msg ) );
          end if;
       end;
     end if;
  end if;
end ParseHashDecrement;

#else

procedure ParseHashDecrement renames not_configured;

#end if;
#if BDB

procedure ParseHashAdd is
  -- Syntax: hash.add( f, s, e );
  -- Ada:    N/A
  fileId     : identifier;
  theFile  : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  itemExpr : unbounded_string;
  itemType : identifier;
  itemId     : identifier;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "add not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_add_t );
  ParseFirstFileParameter( hash_add_t, fileId );
  ParseNextStringParameter( hash_add_t, keyExpr, keyType, uni_string_t );
  expectParameterComma;
  genKindId := identifiers( fileId ).genKind;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     isRecord := true;
     ParseIdentifier( itemId );
     genTypesOk( identifiers( itemId ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     isArray := true;
     ParseIdentifier( itemId );
     genTypesOk( identifiers( itemId ).kind, genKindId );
  -- normal (scalar) expression?
  else
    ParseGenItemParameter( itemExpr, itemType, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              jsonString : unbounded_string;
           begin
              findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
              exists( theFile.hash.session, to_string( keyExpr ) );
           exception when storage_error =>
             err( "storage error raised" );
           when CONSTRAINT_ERROR =>
              err( "constraint_error: value too big" );
           when msg: berkeley_error =>
             if last_error( theFile.hash.session ) = DB_NOTFOUND then
                DoRecordToJson( jsonString, itemId );
                put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
             else
                err( exception_message( msg ) );
             end if;
           end;
        end if;
     elsif isArray then
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              jsonString : unbounded_string;
           begin
              exists( theFile.hash.session, to_string( keyExpr ) );
           exception when storage_error =>
             err( "storage error raised" );
           when CONSTRAINT_ERROR =>
              err( "constraint_error: value too big" );
           when msg: berkeley_error =>
             if last_error( theFile.hash.session ) = DB_NOTFOUND then
                DoArrayToJson( jsonString, itemId );
                put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
             else
                err( exception_message( msg ) );
             end if;
           end;
        end if;
     else
        -- normal scalar expression
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           begin
              exists( theFile.hash.session, to_string( keyExpr ) );
           exception when storage_error =>
             err( "storage error raised" );
           when CONSTRAINT_ERROR =>
              err( "constraint_error: value too big" );
           when msg: berkeley_error =>
             if last_error( theFile.hash.session ) = DB_NOTFOUND then
                put( theFile.hash.session, to_string( keyExpr ), to_string( itemExpr ) );
             else
                err( exception_message( msg ) );
             end if;
           end;
        end if;
     end if;
  end if;
end ParseHashAdd;

#else

procedure ParseHashAdd renames not_configured;

#end if;
#if BDB

procedure ParseHashReplace is
  -- Syntax: hash.replace( f, c | k, v );
  -- Ada:    N/A
  -- Note: the key will not be overwritten if a cursor is used
  fileId     : identifier;
  theFile  : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  itemExpr : unbounded_string;
  itemType : identifier;
  itemId     : identifier;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
  cursId   : identifier := eof_t;
  theCurs  : resPtr;
begin
  if rshOpt then
     err( "replace not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_replace_t );
  ParseFirstFileParameter( hash_replace_t, fileId );
  expectParameterComma;
  if getbaseType( identifiers( token ).kind ) = hash_cursor_t then
     ParseIdentifier( cursId );
     genTypesOk( identifiers( fileId ).genKind, identifiers( cursId ).genKind );
  else
     ParseExpression( keyExpr, keyType );
     baseTypesOk( keyType, uni_string_t );
  end if;
  expectParameterComma;
  genKindId := identifiers( fileId ).genKind;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     isRecord := true;
     ParseIdentifier( itemId );
     genTypesOk( identifiers( itemId ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     isArray := true;
     ParseIdentifier( itemId );
     genTypesOk( identifiers( itemId ).kind, genKindId );
  -- normal (scalar) expression?
  else
    ParseGenItemParameter( itemExpr, itemType, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if cursId /= eof_t then
        -- put where the cursor is
        if isRecord then
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              declare
                 jsonString : unbounded_string;
                 temp_key    : unbounded_string;
                 temp_string : unbounded_string;
              begin
                findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
                get( theFile.hash.session,
                   theCurs.hash_cur.cursor,
                   temp_key,
                   temp_string,
                   DB_C_GET_CURRENT );
                if last_error( theFile.hash.session ) = DB_OK then
                   DoRecordToJson( jsonString, itemId );
                   put( theFile.hash.session,
                        theCurs.hash_cur.cursor,
                        keyExpr, -- this is ignored
                        jsonString,
                        DB_C_PUT_CURRENT );
                end if;
              exception when msg: berkeley_error =>
                err( exception_message( msg ) );
              when CONSTRAINT_ERROR =>
                err( "constraint_error: value too big" );
              end;
           end if;
        elsif isArray then
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              declare
                 temp_key    : unbounded_string;
                 temp_string : unbounded_string;
                 jsonString : unbounded_string;
              begin
                findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
                get( theFile.hash.session,
                   theCurs.hash_cur.cursor,
                   temp_key,
                   temp_string,
                   DB_C_GET_CURRENT );
                if last_error( theFile.hash.session ) = DB_OK then
                   DoArrayToJson( jsonString, itemId );
                   put( theFile.hash.session,
                        theCurs.hash_cur.cursor,
                        keyExpr, -- this is ignored
                        jsonString,
                        DB_C_PUT_CURRENT );
                end if;
              exception when msg: berkeley_error =>
                err( exception_message( msg ) );
              when CONSTRAINT_ERROR =>
                err( "constraint_error: value too big" );
              end;
           end if;
        else
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
             declare
               temp_key    : unbounded_string;
               temp_string : unbounded_string;
             begin
               findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
               get( theFile.hash.session,
                  theCurs.hash_cur.cursor,
                  temp_key,
                  temp_string,
                  DB_C_GET_CURRENT );
               if last_error( theFile.hash.session ) = DB_OK then
                  put( theFile.hash.session,
                       theCurs.hash_cur.cursor,
                       keyExpr, -- this is ignored
                       itemExpr,
                       DB_C_PUT_CURRENT );
               end if;
             exception when msg: berkeley_error =>
               err( exception_message( msg ) );
              when CONSTRAINT_ERROR =>
                err( "constraint_error: value too big" );
             end;
           end if;
        end if;
     else
       -- put, but only if the target exists
        if isRecord then
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              declare
                 jsonString : unbounded_string;
              begin
                exists( theFile.hash.session, to_string( keyExpr ) );
                DoRecordToJson( jsonString, itemId );
                put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
              exception when storage_error =>
                err( "storage error raised" );
              when msg: berkeley_error =>
                 if last_error( theFile.hash.session ) /= DB_NOTFOUND then
                    err( exception_message( msg ) );
                 end if;
              when CONSTRAINT_ERROR =>
                err( "constraint_error: value too big" );
              end;
           end if;
        elsif isArray then
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              declare
                 jsonString : unbounded_string;
              begin
                exists( theFile.hash.session, to_string( keyExpr ) );
                DoArrayToJson( jsonString, itemId );
                put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
              exception when storage_error =>
                err( "storage error raised" );
              when msg: berkeley_error =>
                 if last_error( theFile.hash.session ) /= DB_NOTFOUND then
                    err( exception_message( msg ) );
                 end if;
              when CONSTRAINT_ERROR =>
                err( "constraint_error: value too big" );
              end;
           end if;
        else
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
             begin
                exists( theFile.hash.session, to_string( keyExpr ) );
                put( theFile.hash.session, to_string( keyExpr ), to_string( itemExpr ) );
              exception when storage_error =>
                err( "storage error raised" );
              when msg: berkeley_error =>
                 if last_error( theFile.hash.session ) /= DB_NOTFOUND then
                    err( exception_message( msg ) );
                 end if;
              when CONSTRAINT_ERROR =>
                err( "constraint_error: value too big" );
              end;
           end if;
        end if;
     end if;
  end if;
end ParseHashReplace;

#else

procedure ParseHashReplace renames not_configured;

#end if;
#if BDB

procedure ParseHashAppend is
  -- Syntax: hash.append( f, s, e );
  -- Ada:    N/A
  fileId     : identifier;
  theFile  : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  itemExpr : unbounded_string;
  itemType : identifier;
  oldItem  : unbounded_string;
begin
  if rshOpt then
     err( "append not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_append_t );
  ParseFirstFileParameter( hash_append_t, fileId );
  if getUniType( identifiers( fileId ).genKind ) /= uni_string_t then
     err( "append requires a string item type" );
  end if;
  ParseNextStringParameter( hash_append_t, keyExpr, keyType, uni_string_t );
  ParseLastGenItemParameter( hash_append_t, itemExpr, itemType, identifiers( fileId ).genKind );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
        begin
          get( theFile.hash.session, to_string( keyExpr ), oldItem );
          put( theFile.hash.session, to_string( keyExpr ), to_string( oldItem & itemExpr ) );
        exception when storage_error =>
          err( "storage error raised" );
        when msg: berkeley_error =>
          if last_error( theFile.hash.session ) /= DB_NOTFOUND then
              err( exception_message( msg ) );
          end if;
        when CONSTRAINT_ERROR =>
          err( "constraint_error: value too big" );
        end;
     end if;
  end if;
end ParseHashAppend;

#else

procedure ParseHashAppend renames not_configured;

#end if;
#if BDB

procedure ParseHashPrepend is
  -- Syntax: hash.prepend( f, s, e );
  -- Ada:    N/A
  fileId     : identifier;
  theFile  : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  itemExpr : unbounded_string;
  itemType : identifier;
  oldItem  : unbounded_string;
begin
  if rshOpt then
     err( "prepend not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_prepend_t );
  ParseFirstFileParameter( hash_prepend_t, fileId );
  if getUniType( identifiers( fileId ).genKind ) /= uni_string_t then
     err( "append requires a string item type" );
  end if;
  ParseNextStringParameter( hash_prepend_t, keyExpr, keyType, uni_string_t );
  ParseLastGenItemParameter( hash_prepend_t, itemExpr, itemType, identifiers( fileId ).genKind );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
        begin
          get( theFile.hash.session, to_string( keyExpr ), oldItem );
          put( theFile.hash.session, to_string( keyExpr ), to_string( itemExpr & oldItem ) );
        exception when storage_error =>
          err( "storage error raised" );
        when CONSTRAINT_ERROR =>
          err( "constraint_error: value too big" );
        when msg: berkeley_error =>
          if last_error( theFile.hash.session ) /= DB_NOTFOUND then
              err( exception_message( msg ) );
          end if;
        end;
     end if;
  end if;
end ParseHashPrepend;

#else

procedure ParseHashPrepend renames not_configured;

#end if;
#if BDB

procedure ParseHashFlush is
  -- Syntax: hash.flush( f, flags );
  -- Ada:    bbd.sync( f, flags );
  fileId     : identifier;
  theFile    : resPtr;
begin
  expect( hash_flush_t );
  ParseSingleFileParameter( hash_flush_t, fileId );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
        begin
           sync( theFile.hash.session );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        end;
     end if;
  end if;
end ParseHashFlush;

#else

procedure ParseHashFlush renames not_configured;

#end if;
#if BDB

procedure ParseHashTruncate is
  -- Syntax: hash.truncate( f );
  -- Ada:    bbd.sync( f, cnt );
  fileId     : identifier;
  theFile    : resPtr;
begin
  if rshOpt then
     err( "truncate not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_truncate_t );
  ParseSingleFileParameter( hash_truncate_t, fileId );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
        declare
           cnt : natural;
        begin
           truncate( theFile.hash.session, cnt );
           if trace and cnt > 0 then
              put_trace( cnt'img & " records were erased" );
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        end;
     end if;
  end if;
end ParseHashTruncate;

#else

procedure ParseHashTruncate renames not_configured;

#end if;
#if BDB

--procedure ParseHashNewCursor is
--  -- Syntax: hash.new_cursor( c, t );
--  -- Ada:    N/A
--  resId : resHandleId;
--  ref : reference;
--  genKindId : identifier;
--begin
--  expect( hash_new_cursor_t );
--  ParseFirstOutParameter( ref, hash_cursor_t );
--  baseTypesOK( ref.kind, hash_cursor_t );
--  expect( symbol_t, "," );
--  ParseIdentifier( genKindId );
--  if class_ok( genKindId, typeClass, subClass ) then
--     --DEBUG
--     null;
--     --if identifiers( genKindId ).list then
--     --   err( "element type should be a scalar type" );
--     --elsif identifiers( getBaseType( genKindId ) ).kind = root_record_t then
--     --   err( "element type should be a scalar type" );
--     --end if;
--  end if;
--  identifiers( ref.id ).genKind := genKindId;
--  expect( symbol_t, ")" );
--  if isExecutingCommand then
--     identifiers( ref.id ).resource := true;
--     declareResource( resId, hash_cursor, getIdentifierBlock( ref.id ) );
--     AssignParameter( ref, to_unbounded_string( resId ) );
--     -- Note: this won't work if the cursor is in an array or other
--     -- aggregate type
--     identifiers( ref.id ).wasWritten := true;
--  end if;
--end ParseHashNewCursor;

#else

--procedure ParseHashNewCursor renames not_configured;

#end if;
#if BDB

procedure ParseHashOpenCursor is
  -- Syntax: hash_io.open_cursor( f, c );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
begin
  expect( hash_open_cursor_t );
  ParseFirstFileParameter( hash_open_cursor_t, fileId );
  ParseLastCursorParameter( hash_open_cursor_t, cursId );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
     if isVerifiedOpenFile( fileId, theFile ) then
        findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
        if theCurs.hash_cur.isOpen then
           err( "cursor " &
              optional_yellow( to_string( identifiers( cursId ).name ) ) &
              " is already open" );
        else
           new_berkeley_cursor( theFile.hash.session, theCurs.hash_cur.cursor );
           theCurs.hash_cur.session := theFile.hash.session;
           theCurs.hash_cur.isOpen := true;
        end if;
     end if;
  end if;
end ParseHashOpenCursor;

#else

procedure ParseHashOpenCursor renames not_configured;

#end if;
#if BDB

procedure ParseHashCloseCursor is
  -- Syntax: hash_io.close_cursor( f,c );
  -- Ada:    bdb.close_cursor( f,c );
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
begin
  expect( hash_close_cursor_t );
  ParseFirstFileParameter( hash_close_cursor_t, fileId );
  ParseLastCursorParameter( hash_close_cursor_t, cursId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
           if not theCurs.hash_cur.isOpen then
              err( "cursor " &
                 optional_yellow( to_string( identifiers( cursId ).name ) ) &
                " is not open" );
           else
              close( theFile.hash.session, theCurs.hash_cur.cursor );
              theCurs.hash_cur.isOpen := false;
           end if;

        end if;
     exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashCloseCursor;

#else

procedure ParseHashCloseCursor renames not_configured;

#end if;
#if BDB

procedure ParseHashGetFirst is
  -- Syntax: hash_io.get_first( f, c, k, v );
  -- Ada:    bdb.get_first( f );
  -- Note: Unlike Ada lists, Berkeley will also return the element when
  -- positioning the cursor.
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyRef     : reference;
  valRef     : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "get_first not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_get_first_t );
  ParseFirstFileParameter( hash_get_first_t, fileId );
  ParseNextCursorParameter( hash_get_first_t, cursId );
  genKindId := identifiers( fileId ).genKind;
  genTypesOk( genKindId, identifiers( cursId ).genKind );
  ParseNextOutParameter( hash_get_first_t, keyRef, string_t );
  baseTypesOK( keyRef.kind, string_t );
  if syntax_check and then not error_found then
     identifiers( keyRef.id ).wasWritten := true;
     identifiers( keyRef.id ).writtenByThread := getThreadName;
  end if;
  expectParameterComma;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  else
     -- This will still auto-declare scalar values
     ParseOutParameter(  valRef, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              key : unbounded_string;
              jsonString : unbounded_string;
           begin
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                   " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      jsonString,
                      DB_C_GET_FIRST );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    DoJsonToRecord( valRef.id, jsonString );
                 end if;
              end if;
           exception when msg: berkeley_error =>
              err( exception_message( msg ) );
           when STORAGE_ERROR =>
              err( "storage_error raised" );
           end;
        end if;
     elsif isArray then
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              key : unbounded_string;
              jsonString : unbounded_string;
           begin
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                   " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      jsonString,
                      DB_C_GET_FIRST );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    DoJsonToArray( valRef.id, jsonString );
                 end if;
              end if;
           exception when msg: berkeley_error =>
              err( exception_message( msg ) );
           when STORAGE_ERROR =>
              err( "storage_error raised" );
           end;
        end if;
     else
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           declare
              key : unbounded_string;
              data : unbounded_string;
           begin
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                   " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      data,
                      DB_C_GET_FIRST );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    AssignParameter( valRef, data );
                 end if;
              end if;
           exception when msg: berkeley_error =>
              err( exception_message( msg ) );
           when STORAGE_ERROR =>
              err( "storage_error raised" );
           end;
        end if;
     end if;
  end if;
end ParseHashGetFirst;

#else

procedure ParseHashGetFirst renames not_configured;

#end if;
#if BDB

procedure ParseHashGetNext is
  -- Syntax: hash_io.get_next( f, c, k, v );
  -- Ada:    bdb.get( f );
  -- Note: Unlike Ada lists, Berkeley will also return the element when
  -- positioning the cursor.
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyRef     : reference;
  valRef     : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "get_next not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_get_next_t );
  ParseFirstFileParameter( hash_get_next_t, fileId );
  ParseNextCursorParameter( hash_get_next_t, cursId );
  genKindId := identifiers( fileId ).genKind;
  genTypesOk( genKindId, identifiers( cursId ).genKind );
  ParseNextOutParameter( hash_get_next_t, keyRef, string_t );
  baseTypesOK( keyRef.kind, string_t );
  expectParameterComma;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  else
     -- This will still auto-declare scalar values
     ParseOutParameter(  valRef, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      jsonString,
                      DB_C_GET_NEXT );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    DoJsonToRecord( valRef.id, jsonString );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     elsif isArray then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      jsonString,
                      DB_C_GET_NEXT );
                if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    DoJsonToArray( valRef.id, jsonString );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     else
        declare
           key : unbounded_string;
           data : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      data,
                      DB_C_GET_NEXT );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    AssignParameter( valRef, data );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     end if;
  end if;
end ParseHashGetNext;

#else

procedure ParseHashGetNext renames not_configured;

#end if;
#if BDB

procedure ParseHashGetLast is
  -- Syntax: hash_io.get_last( f, c, k, v );
  -- Ada:    bdb.get( f );
  -- Note: Unlike Ada lists, Berkeley will also return the element when
  -- positioning the cursor.
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyRef     : reference;
  valRef     : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "get_last not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_get_last_t );
  ParseFirstFileParameter( hash_get_last_t, fileId );
  ParseNextCursorParameter( hash_get_last_t, cursId );
  genKindId := identifiers( fileId ).genKind;
  genTypesOk( genKindId, identifiers( cursId ).genKind );
  ParseNextOutParameter( hash_get_last_t, keyRef, string_t );
  baseTypesOK( keyRef.kind, string_t );
  if syntax_check and then not error_found then
     identifiers( keyRef.id ).wasWritten := true;
     identifiers( keyRef.id ).writtenByThread := getThreadName;
  end if;
  expectParameterComma;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  else
     -- This will still auto-declare scalar values
     ParseOutParameter(  valRef, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      jsonString,
                      DB_C_GET_LAST );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    DoJsonToRecord( valRef.id, jsonString );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     elsif isArray then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      jsonString,
                      DB_C_GET_LAST );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    DoJsonToArray( valRef.id, jsonString );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     else
        declare
           key : unbounded_string;
           data : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      data,
                      DB_C_GET_LAST );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    AssignParameter( valRef, data );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     end if;
  end if;
end ParseHashGetLast;

#else

procedure ParseHashGetLast renames not_configured;

#end if;
#if BDB

procedure ParseHashGetPrevious is
  -- Syntax: hash_io.get_previous( f, c, k, v );
  -- Ada:    bdb.get( f );
  -- Note: Unlike Ada lists, Berkeley will also return the element when
  -- positioning the cursor.
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyRef     : reference;
  valRef     : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "get_previous not allowed in a " & optional_yellow( "restricted shell" ) );
  end if;
  expect( hash_get_previous_t );
  ParseFirstFileParameter( hash_get_previous_t, fileId );
  ParseNextCursorParameter( hash_get_previous_t, cursId );
  genKindId := identifiers( fileId ).genKind;
  genTypesOk( genKindId, identifiers( cursId ).genKind );
  ParseNextOutParameter( hash_get_previous_t, keyRef, string_t );
  baseTypesOK( keyRef.kind, string_t );
  expectParameterComma;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
     if syntax_check and then not error_found then
        identifiers( valRef.id ).wasWritten := true;
        identifiers( valRef.id ).writtenByThread := getThreadName;
     end if;
  else
     -- This will still auto-declare scalar values
     ParseOutParameter(  valRef, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      jsonString,
                      DB_C_GET_PREV );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    DoJsonToRecord( valRef.id, jsonString );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     elsif isArray then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      jsonString,
                      DB_C_GET_PREV );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    DoJsonToArray( valRef.id, jsonString );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     else
        declare
           key : unbounded_string;
           data : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
           if isVerifiedOpenFile( fileId, theFile ) then
              findResource( to_resource_id( identifiers( cursId ).value.all ), theCurs );
              if not theCurs.hash_cur.isOpen then
                 err( "cursor " &
                    optional_yellow( to_string( identifiers( cursId ).name ) ) &
                    " is not open" );
              else
                 get( theFile.hash.session,
                      theCurs.hash_cur.cursor,
                      key,
                      data,
                      DB_C_GET_PREV );
                 if last_error( theFile.hash.session ) = DB_OK then
                    AssignParameter( keyRef, key );
                    AssignParameter( valRef, data );
                 end if;
              end if;
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        end;
     end if;
  end if;
end ParseHashGetPrevious;
#else

procedure ParseHashGetPrevious renames not_configured;

#end if;
#if BDB

procedure ParseHashWillRaise( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: b := hash.will_raise( f );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
begin
  kind := boolean_t;
  expect( hash_will_raise_t );
  ParseSingleFileParameter( hash_will_raise_t, fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           result := to_bush_boolean( will_raise( theFile.hash.session ) );
        end if;
     exception when berkeley_error =>
        result := to_bush_boolean( false );
     end;
  end if;
end ParseHashWillRaise;

#else

procedure ParseHashWillRaise( result : out unbounded_string; kind : out identifier ) renames not_configured;

#end if;
#if BDB

procedure ParseHashLastError( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: n := hash_io.last_error( f );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
begin
  kind := bdb_db_error_t;
  expect( hash_last_error_t );
  ParseSingleFileParameter( hash_last_error_t, fileId );
  if isExecutingCommand then
     begin
       findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
       if isVerifiedOpenFile( fileId, theFile ) then
          result := to_unbounded_string( db_error'image( last_error( theFile.hash.session ) ) );
       end if;
     exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashLastError;

#else

procedure ParseHashLastError( result : out unbounded_string; kind : out identifier ) renames not_configured;

#end if;
#if BDB

procedure ParseHashRaiseExceptions is
  -- Syntax: hash_io.raise_exceptions( f, b );
  -- Ada:    bdb.raise_exceptions
  -- this is impacted by --trace
  fileId     : identifier;
  theFile    : resPtr;
  boolExpr   : unbounded_string;
  boolType   : identifier;
begin
  expect( hash_raise_exceptions_t );
  ParseFirstFileParameter( hash_raise_exceptions_t, fileId );
  ParseLastEnumParameter( hash_raise_exceptions_t, boolExpr, boolType, boolean_t );
  if isExecutingCommand then
     declare
       raise_them : constant boolean := boolExpr = to_unbounded_string( "1" );
     begin
        findResource( to_resource_id( identifiers( fileId ).value.all ), theFile );
        if isVerifiedOpenFile( fileId, theFile ) then
           raise_exceptions( theFile.hash.session, raise_them, boolean( traceOpt ) );
        end if;
     exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashRaiseExceptions;

#else

procedure ParseHashRaiseExceptions renames not_configured;

#end if;

-----------------------------------------------------------------------------

procedure StartupHashIO is
begin
  declareNamespace( "hash_io" );

  declareIdent( hash_file_t,   "hash_io.file", variable_t, genericTypeClass );
  identifiers( hash_file_t ).usage := limitedUsage;
  identifiers( hash_file_t ).resource := true;
  declareIdent( hash_cursor_t, "hash_io.cursor", variable_t, genericTypeClass );
  identifiers( hash_cursor_t ).usage := limitedUsage;
  identifiers( hash_cursor_t ).resource := true;

  --declareProcedure( hash_new_file_t,  "hash_io.new_file", ParseHashNewFile'access );
  declareProcedure( hash_clear_t,     "hash_io.clear",    ParseHashClear'access );

  declareProcedure( hash_recover_t,   "hash_io.recover",  ParseHashRecover'access );
  declareProcedure( hash_create_t,    "hash_io.create",   ParseHashCreate'access );
  declareProcedure( hash_close_t,     "hash_io.close",    ParseHashClose'access );
  declareProcedure( hash_open_t,      "hash_io.open",     ParseHashOpen'access );
  declareFunction(  hash_is_open_t,   "hash_io.is_open",  ParseHashIsOpen'access );
  declareFunction(  hash_name_t,      "hash_io.name",     ParseHashName'access );
  declareProcedure( hash_delete_t,    "hash_io.delete",   ParseHashDelete'access );
  declareProcedure( hash_flush_t,     "hash_io.flush",    ParseHashFlush'access );
  declareProcedure( hash_truncate_t,  "hash_io.truncate",  ParseHashTruncate'access );

  declareProcedure( hash_set_t,       "hash_io.set",      ParseHashSet'access );
  declareProcedure( hash_get_t,       "hash_io.get",      ParseHashGet'access );
  declareFunction(  hash_has_element_t, "hash_io.has_element",  ParseHashHasElement'access );
  declareProcedure( hash_remove_t,    "hash_io.remove",      ParseHashRemove'access );
  declareProcedure( hash_increment_t, "hash_io.increment",ParseHashIncrement'access );
  declareProcedure( hash_decrement_t, "hash_io.decrement",ParseHashDecrement'access );
  declareProcedure( hash_add_t,       "hash_io.add", ParseHashAdd'access );
  declareProcedure( hash_replace_t,   "hash_io.replace", ParseHashReplace'access );
  declareProcedure( hash_append_t,    "hash_io.append", ParseHashAppend'access );
  declareProcedure( hash_prepend_t,   "hash_io.prepend", ParseHashPrepend'access );

  --declareProcedure( hash_new_cursor_t,  "hash_io.new_cursor", ParseHashNewCursor'access );
  declareProcedure( hash_open_cursor_t,  "hash_io.open_cursor", ParseHashOpenCursor'access );
  declareProcedure( hash_close_cursor_t,  "hash_io.close_cursor", ParseHashCloseCursor'access );
  declareProcedure( hash_get_first_t,     "hash_io.get_first", ParseHashGetFirst'access );
  declareProcedure( hash_get_next_t,      "hash_io.get_next", ParseHashGetNext'access );
  declareProcedure( hash_get_previous_t,  "hash_io.get_previous", ParseHashGetPrevious'access );
  declareProcedure( hash_get_last_t,      "hash_io.get_last", ParseHashGetLast'access );

  declareFunction( hash_will_raise_t, "hash_io.will_raise",  ParseHashWillRaise'access );
  declareFunction( hash_last_error_t, "hash_io.last_error",  ParseHashLastError'access );
  declareProcedure( hash_raise_exceptions_t, "hash_io.raise_exceptions", ParseHashRaiseExceptions'access );

-- TODO: assemble and disassemble - are they helpful for potentially huge trees?
-- TODO: clear (cursor) - just for consistency
-- TODO: truncate
-- TODO: reset?  are in_file, etc. helpful to define here?

  declareNamespaceClosed( "hash_io" );

end StartupHashIO;

procedure ShutdownHashIO is
begin
  null;
end ShutdownHashIO;

end parser_hash_io;
